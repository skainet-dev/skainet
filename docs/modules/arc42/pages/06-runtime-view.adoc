= Runtime View

[role="arc42help"]
****
The runtime view describes concrete behavior and interactions of the system's building blocks in form of scenarios for the following purposes:

* important use cases or features: how do building blocks execute them?
* interactions at critical external interfaces: how do building blocks cooperate with users and neighboring systems?
* operation and administration: launch, start-up, stop
* error and exception scenarios
****

== Tensor Creation and Initialization

=== Scenario: Creating a Tensor from Data

[plantuml, tensor-creation, svg]
....
!theme plain

actor "Application" as app
participant "CpuTensorFP32" as tensor
participant "Shape" as shape
participant "FloatArray" as data

app -> tensor : fromArray(shape, data)
activate tensor

tensor -> shape : validate dimensions
activate shape
shape --> tensor : validation result
deactivate shape

alt validation successful
    tensor -> tensor : create instance
    tensor -> data : copy/reference data
    tensor --> app : Tensor<FP32, Float>
else validation failed
    tensor --> app : throw IllegalArgumentException
end

deactivate tensor
....

*Description*: Application creates a tensor by providing shape and data array.

*Key Steps*:
1. Application calls factory method with shape and data
2. Shape validation ensures data array size matches dimensions
3. Tensor instance created with validated parameters
4. Reference or copy of data array stored internally

*Error Handling*:
* Invalid shape dimensions → `IllegalArgumentException`
* Data array size mismatch → `IllegalArgumentException`
* Null parameters → `NullPointerException`

== Backend Operations

=== Scenario: Matrix Multiplication

[plantuml, matrix-multiplication, svg]
....
!theme plain

actor "Application" as app
participant "CpuBackend" as backend
participant "Tensor A" as tensorA
participant "Tensor B" as tensorB
participant "Result Tensor" as result

app -> backend : matmul(tensorA, tensorB)
activate backend

backend -> tensorA : validate shape
backend -> tensorB : validate shape

alt shapes compatible
    backend -> backend : calculate result shape
    backend -> result : create result tensor
    activate result
    
    loop for each row i
        loop for each column j
            backend -> tensorA : get row i
            backend -> tensorB : get column j
            backend -> backend : dot product
            backend -> result : set(i, j, value)
        end
    end
    
    backend --> app : result tensor
    deactivate result
else incompatible shapes
    backend --> app : throw IllegalArgumentException
end

deactivate backend
....

*Description*: Matrix multiplication between two tensors using CPU backend.

*Performance Characteristics*:
* Time Complexity: O(n³) for square matrices
* Space Complexity: O(n²) for result storage
* Memory Access: Sequential for optimal cache utilization

*Validation Rules*:
* Matrix A columns must equal Matrix B rows
* Both tensors must be 2-dimensional
* Compatible data types required

== Performance Benchmarking

=== Scenario: Benchmark Execution

[plantuml, benchmark-execution, svg]
....
!theme plain

actor "Test Runner" as test
participant "BenchmarkRunner" as runner
participant "Operation" as op
participant "Statistics" as stats

test -> runner : benchmark(name, warmup, measurement, operation)
activate runner

loop warmup runs
    runner -> op : execute()
    runner -> runner : discard result
end

loop measurement runs
    runner -> runner : start timer
    runner -> op : execute()
    runner -> runner : stop timer
    runner -> runner : record time
end

runner -> stats : calculate statistics
activate stats
stats -> stats : compute mean, std dev
stats -> stats : detect outliers
stats --> runner : performance metrics
deactivate stats

runner --> test : BenchmarkResult
deactivate runner
....

*Description*: Performance benchmarking framework measuring operation execution time.

*Measurement Process*:
1. Warmup phase to stabilize JVM performance
2. Measurement phase with precise timing
3. Statistical analysis of results
4. Outlier detection and removal

*Metrics Collected*:
* Execution time (mean, standard deviation, percentiles)
* Memory usage patterns
* Performance scaling characteristics
* Throughput measurements

== Error Handling Scenarios

=== Scenario: Invalid Tensor Operation

[plantuml, error-handling, svg]
....
!theme plain

actor "Application" as app
participant "CpuBackend" as backend
participant "ValidationUtils" as validator

app -> backend : plus(tensorA, tensorB)
activate backend

backend -> validator : validateShapeCompatibility(shapeA, shapeB)
activate validator

alt shapes compatible
    validator --> backend : validation passed
    deactivate validator
    backend -> backend : perform addition
    backend --> app : result tensor
else shapes incompatible
    validator --> backend : validation failed
    deactivate validator
    backend --> app : throw ShapeIncompatibilityException
end

deactivate backend
....

*Common Error Scenarios*:
* Shape incompatibility in operations
* Invalid tensor dimensions
* Null pointer references
* Out of memory conditions

*Error Recovery Strategies*:
* Graceful degradation with fallback operations
* Clear error messages with suggested fixes
* Resource cleanup on failure
* Performance impact logging

== Multiplatform Deployment

=== JVM Runtime Scenario

[plantuml, jvm-runtime, svg]
....
!theme plain

package "JVM Platform" {
    participant "Application" as app
    participant "CpuBackend" as backend
    participant "FloatArray" as array
    participant "JVM Math" as math
}

app -> backend : matrix operation
backend -> array : create native array
backend -> math : utilize JVM optimizations
math -> backend : optimized result
backend -> app : tensor result
....

=== Native Runtime Scenario

[plantuml, native-runtime, svg]
....
!theme plain

package "Native Platform" {
    participant "Application" as app
    participant "CpuBackend" as backend
    participant "NativeArray" as array
    participant "BLAS Library" as blas
}

app -> backend : matrix operation
backend -> array : allocate native memory
backend -> blas : call optimized routines
blas -> backend : native computation result
backend -> app : tensor result
....

*Platform-Specific Optimizations*:
* JVM: Leverages HotSpot optimizations and efficient garbage collection
* Native: Direct memory access and BLAS library integration
* JavaScript: WebAssembly modules for performance-critical operations

== Lifecycle Management

=== System Startup

1. Backend registration and discovery
2. Platform capability detection
3. Performance baseline establishment
4. Resource pool initialization

=== Operation Execution

1. Input validation and preprocessing
2. Backend selection based on operation type
3. Computation execution with monitoring
4. Result validation and postprocessing

=== Resource Cleanup

1. Tensor memory deallocation
2. Backend resource cleanup
3. Performance metrics collection
4. Graceful shutdown procedures