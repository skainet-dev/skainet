= Matrix Operations
:toc: left
:toclevels: 3
:sectanchors:
:sectlinks:

Master matrix operations in SKaiNET with practical examples that form the foundation of machine learning and scientific computing.

== Matrix Multiplication Fundamentals

Matrix multiplication is the cornerstone of linear algebra and machine learning. SKaiNET provides efficient matrix multiplication through the `matmul` operation.

=== Basic Matrix Multiplication

[source,kotlin]
----
val backend = CpuBackend()

// Create two matrices
val A = CpuTensorFP32.fromArray(
    Shape(2, 3),
    floatArrayOf(1f, 2f, 3f, 4f, 5f, 6f)
)
// A = [[1, 2, 3],
//      [4, 5, 6]]

val B = CpuTensorFP32.fromArray(
    Shape(3, 2),
    floatArrayOf(7f, 8f, 9f, 10f, 11f, 12f)
)
// B = [[7,  8 ],
//      [9,  10],
//      [11, 12]]

// Matrix multiplication: A × B
val C = backend.matmul(A, B)
// C = [[58,  64],    // 1×7 + 2×9 + 3×11 = 58, 1×8 + 2×10 + 3×12 = 64
//      [139, 154]]   // 4×7 + 5×9 + 6×11 = 139, 4×8 + 5×10 + 6×12 = 154

println("Result shape: ${C.shape}")  // Shape(2, 2)
println("C[0,0] = ${C[0, 0]}, C[0,1] = ${C[0, 1]}")
println("C[1,0] = ${C[1, 0]}, C[1,1] = ${C[1, 1]}")
----

== Practical Example: Linear Transformations

Transform 2D points using transformation matrices:

[source,kotlin]
----
// Rotation matrix for 45 degrees
fun createRotationMatrix(angleRadians: Float): CpuTensorFP32 {
    val cos = kotlin.math.cos(angleRadians)
    val sin = kotlin.math.sin(angleRadians)
    return CpuTensorFP32.fromArray(
        Shape(2, 2),
        floatArrayOf(cos, -sin, sin, cos)
    )
}

// Scaling matrix
fun createScalingMatrix(scaleX: Float, scaleY: Float): CpuTensorFP32 {
    return CpuTensorFP32.fromArray(
        Shape(2, 2),
        floatArrayOf(scaleX, 0f, 0f, scaleY)
    )
}

val backend = CpuBackend()

// Original points: (1,0), (0,1), (-1,0), (0,-1) - unit circle
val points = CpuTensorFP32.fromArray(
    Shape(2, 4),
    floatArrayOf(1f, 0f, -1f, 0f, 0f, 1f, 0f, -1f)
)

// Rotate by 45 degrees (π/4 radians)
val rotationMatrix = createRotationMatrix(kotlin.math.PI.toFloat() / 4)
val rotatedPoints = backend.matmul(rotationMatrix, points)

// Scale by factor of 2
val scalingMatrix = createScalingMatrix(2f, 2f)
val scaledAndRotated = backend.matmul(scalingMatrix, rotatedPoints)

println("Original points:")
for (i in 0 until 4) {
    println("(${points[0, i]}, ${points[1, i]})")
}

println("After rotation and scaling:")
for (i in 0 until 4) {
    println("(${scaledAndRotated[0, i]}, ${scaledAndRotated[1, i]})")
}
----

== Practical Example: System of Linear Equations

Solve Ax = b using matrix operations (simplified Gaussian elimination approach):

[source,kotlin]
----
// Solve a 2x2 system: 
// 3x + 2y = 7
// 1x + 4y = 11
fun solveLinearSystem2x2(
    A: CpuTensorFP32, 
    b: CpuTensorFP32, 
    backend: CpuBackend
): CpuTensorFP32 {
    // For 2x2 system, we can use Cramer's rule
    // x = (b1*a22 - b2*a12) / det
    // y = (a11*b2 - a21*b1) / det
    
    val a11 = A[0, 0]; val a12 = A[0, 1]
    val a21 = A[1, 0]; val a22 = A[1, 1]
    val b1 = b[0]; val b2 = b[1]
    
    val determinant = a11 * a22 - a12 * a21
    
    val x = (b1 * a22 - b2 * a12) / determinant
    val y = (a11 * b2 - a21 * b1) / determinant
    
    return CpuTensorFP32.fromArray(Shape(2), floatArrayOf(x, y))
}

val backend = CpuBackend()

// Coefficient matrix A
val A = CpuTensorFP32.fromArray(
    Shape(2, 2),
    floatArrayOf(3f, 2f, 1f, 4f)
)

// Constants vector b
val b = CpuTensorFP32.fromArray(Shape(2), floatArrayOf(7f, 11f))

val solution = solveLinearSystem2x2(A, b, backend)

println("Solution: x = ${solution[0]}, y = ${solution[1]}")
// Should output: x = 1.0, y = 2.0

// Verify: A × solution should equal b
val verification = backend.matmul(A, solution.reshape(Shape(2, 1)))
println("Verification: Ax = [${verification[0, 0]}, ${verification[1, 0]}]")
----

== Vector Operations

=== Dot Product

Calculate the dot product of two vectors:

[source,kotlin]
----
val backend = CpuBackend()

val vector1 = CpuTensorFP32.fromArray(Shape(3), floatArrayOf(1f, 2f, 3f))
val vector2 = CpuTensorFP32.fromArray(Shape(3), floatArrayOf(4f, 5f, 6f))

// Dot product using the backend
val dotProduct = backend.dot(vector1, vector2)
println("Dot product: $dotProduct")  // 1×4 + 2×5 + 3×6 = 32

// Alternative: using matrix multiplication for dot product
val dotProductAlt = backend.matmul(
    vector1.reshape(Shape(1, 3)), 
    vector2.reshape(Shape(3, 1))
)[0, 0]
println("Dot product (alternative): $dotProductAlt")
----

=== Vector-Matrix Operations

[source,kotlin]
----
val backend = CpuBackend()

// Row vector × Matrix
val rowVector = CpuTensorFP32.fromArray(Shape(1, 3), floatArrayOf(1f, 2f, 3f))
val matrix = CpuTensorFP32.fromArray(
    Shape(3, 4),
    floatArrayOf(1f, 2f, 3f, 4f, 5f, 6f, 7f, 8f, 9f, 10f, 11f, 12f)
)

val result1 = backend.matmul(rowVector, matrix)
println("Row vector × Matrix result shape: ${result1.shape}")  // Shape(1, 4)

// Matrix × Column vector  
val columnVector = CpuTensorFP32.fromArray(Shape(4, 1), floatArrayOf(1f, 2f, 3f, 4f))
val result2 = backend.matmul(matrix, columnVector)
println("Matrix × Column vector result shape: ${result2.shape}")  // Shape(3, 1)
----

== Practical Example: Image Convolution (Simplified)

Implement a basic image filter using matrix operations:

[source,kotlin]
----
// Simple 3x3 edge detection kernel
fun createEdgeDetectionKernel(): CpuTensorFP32 {
    return CpuTensorFP32.fromArray(
        Shape(3, 3),
        floatArrayOf(
            -1f, -1f, -1f,
            -1f,  8f, -1f,
            -1f, -1f, -1f
        )
    )
}

// Apply kernel to a 3x3 image patch
fun applyKernel(
    imagePatch: CpuTensorFP32, 
    kernel: CpuTensorFP32, 
    backend: CpuBackend
): Float {
    // Element-wise multiplication and sum
    val multiplied = with(backend) { imagePatch * kernel }
    
    var sum = 0f
    for (i in 0 until 3) {
        for (j in 0 until 3) {
            sum += multiplied[i, j]
        }
    }
    return sum
}

val backend = CpuBackend()

// Sample 3x3 image patch (grayscale values)
val imagePatch = CpuTensorFP32.fromArray(
    Shape(3, 3),
    floatArrayOf(
        100f, 100f, 100f,
        100f, 200f, 100f,  // Bright center
        100f, 100f, 100f
    )
)

val kernel = createEdgeDetectionKernel()
val filterResponse = applyKernel(imagePatch, kernel, backend)

println("Edge detection response: $filterResponse")
// High value indicates an edge was detected
----

== Practical Example: Principal Component Analysis (PCA) Setup

Prepare data for dimensionality reduction:

[source,kotlin]
----
// Center the data by subtracting the mean
fun centerData(data: CpuTensorFP32, backend: CpuBackend): CpuTensorFP32 {
    val numSamples = data.shape.dimensions[0]
    val numFeatures = data.shape.dimensions[1]
    
    // Calculate means for each feature
    val means = FloatArray(numFeatures) { featureIndex ->
        var sum = 0f
        for (sampleIndex in 0 until numSamples) {
            sum += data[sampleIndex, featureIndex]
        }
        sum / numSamples
    }
    
    // Subtract means from each feature
    val centered = FloatArray(numSamples * numFeatures) { i ->
        val sampleIndex = i / numFeatures
        val featureIndex = i % numFeatures
        data[sampleIndex, featureIndex] - means[featureIndex]
    }
    
    return CpuTensorFP32.fromArray(data.shape, centered)
}

val backend = CpuBackend()

// Sample dataset: 4 samples, 3 features
val rawData = CpuTensorFP32.fromArray(
    Shape(4, 3),
    floatArrayOf(
        1f, 2f, 3f,
        4f, 5f, 6f,
        7f, 8f, 9f,
        10f, 11f, 12f
    )
)

val centeredData = centerData(rawData, backend)

println("Original data means per feature:")
for (feature in 0 until 3) {
    var sum = 0f
    for (sample in 0 until 4) {
        sum += rawData[sample, feature]
    }
    println("Feature $feature mean: ${sum / 4}")
}

println("Centered data means per feature (should be ~0):")
for (feature in 0 until 3) {
    var sum = 0f
    for (sample in 0 until 4) {
        sum += centeredData[sample, feature]
    }
    println("Feature $feature mean: ${sum / 4}")
}
----

== Performance Tips for Matrix Operations

=== Choose Appropriate Shapes

Matrix multiplication performance depends on shape:

[source,kotlin]
----
val backend = CpuBackend()

// Efficient: Multiply smaller matrices when possible
val A = CpuTensorFP32.fromArray(Shape(100, 50), FloatArray(100 * 50) { it.toFloat() })
val B = CpuTensorFP32.fromArray(Shape(50, 200), FloatArray(50 * 200) { it.toFloat() })

// This is more efficient than creating one large matrix
val result = backend.matmul(A, B)  // Shape(100, 200)
----

=== Batch Operations

Process multiple matrices together when possible:

[source,kotlin]
----
// Instead of multiple small operations, batch them
val backend = CpuBackend()

// Batch matrix: multiple samples in one tensor
val batchMatrix = CpuTensorFP32.fromArray(
    Shape(32, 128),  // 32 samples, 128 features each
    FloatArray(32 * 128) { kotlin.random.Random.nextFloat() }
)

val weights = CpuTensorFP32.fromArray(
    Shape(128, 64),  // Transform to 64 features
    FloatArray(128 * 64) { kotlin.random.Random.nextFloat() }
)

// One operation processes all samples
val batchResult = backend.matmul(batchMatrix, weights)  // Shape(32, 64)
----

== Next Steps

With matrix operations mastered, you're ready for more advanced topics in xref:linear-algebra.adoc[Linear Algebra Examples] and xref:neural-network-basics.adoc[Neural Network Basics].

[TIP]
====
Matrix operations are the building blocks of machine learning. Understanding how data flows through these transformations is key to designing effective neural networks and understanding algorithm behavior.
====